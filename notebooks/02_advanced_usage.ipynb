{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e4721cf",
   "metadata": {},
   "source": [
    "# Advanced Usage of reLAISS\n",
    "### Authors: Evan Reynolds and Alex Gagliano\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates advanced features of the reLAISS library for finding similar astronomical transients. While the basic_usage.ipynb notebook covered the fundamental functionality, here we'll explore more sophisticated techniques that give you greater flexibility and power in your analysis.\n",
    "\n",
    "These advanced features allow you to customize how reLAISS processes and analyzes data, including dimensionality reduction, theorized lightcurves, host galaxy swapping, fine-tuning of algorithm parameters, visualization tools, and advanced anomaly detection.\n",
    "\n",
    "## Topics Covered\n",
    "1. Using PCA for dimensionality reduction\n",
    "2. Creating and using theorized lightcurves\n",
    "3. Swapping host galaxies\n",
    "4. Setting maximum neighbor distances\n",
    "5. Tweaking ANNOY parameters\n",
    "6. Making corner plots\n",
    "7. Advanced anomaly detection with parameter tuning\n",
    "8. Host swapping in anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068a042a",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary packages and create the required directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8865be62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import relaiss as rl\n",
    "import astropy.units as u\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs('./figures', exist_ok=True)\n",
    "os.makedirs('./sfddata-master', exist_ok=True)\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "os.makedirs('./timeseries', exist_ok=True)\n",
    "\n",
    "def create_theorized_lightcurve():\n",
    "    \"\"\"Create a simple theorized lightcurve for demonstration.\"\"\"\n",
    "    # Create a simple Gaussian lightcurve\n",
    "    times = np.linspace(-20, 50, 50)  # Days relative to peak\n",
    "    g_mags = 18 + 5 * np.exp(-(times**2) / (2 * 15**2))  # Gaussian with peak at mag 18\n",
    "    r_mags = 19 + 4 * np.exp(-(times**2) / (2 * 20**2))  # Gaussian with peak at mag 19\n",
    "    \n",
    "    # Create DataFrame in the format expected by reLAISS\n",
    "    g_data = pd.DataFrame({\n",
    "        'ant_mjd': times + 59000,  # Add offset to get realistic MJD values\n",
    "        'ant_mag': g_mags,\n",
    "        'ant_magerr': np.ones_like(times) * 0.1,  # Constant uncertainty\n",
    "        'ant_passband': ['g'] * len(times),  # Antares passband\n",
    "        'ant_ra': np.full_like(times, 180.0, dtype=float),  # RA in degrees\n",
    "        'ant_dec': np.full_like(times, 45.0, dtype=float),  # Dec in degrees\n",
    "    })\n",
    "    \n",
    "    r_data = pd.DataFrame({\n",
    "        'ant_mjd': times + 59000,  # Add offset to get realistic MJD values\n",
    "        'ant_mag': r_mags,\n",
    "        'ant_magerr': np.ones_like(times) * 0.1,  # Constant uncertainty\n",
    "        'ant_passband': ['R'] * len(times),  # Antares passband - R uppercase for r-band\n",
    "        'ant_ra': np.full_like(times, 180.0, dtype=float),  # RA in degrees\n",
    "        'ant_dec': np.full_like(times, 45.0, dtype=float),  # Dec in degrees\n",
    "    })\n",
    "    \n",
    "    # Combine g and r band data\n",
    "    lc_df = pd.concat([g_data, r_data], ignore_index=True)\n",
    "    \n",
    "    return lc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735ea52c",
   "metadata": {},
   "source": [
    "## Initialize the ReLAISS Client\n",
    "\n",
    "We'll start by creating a ReLAISS client instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a389f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the client\n",
    "client = rl.ReLAISS()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659c10b4",
   "metadata": {},
   "source": [
    "## 1. Using PCA for Dimensionality Reduction\n",
    "\n",
    "PCA (Principal Component Analysis) can be used to reduce the dimensionality of the feature space while preserving most of the variance. This has several benefits:\n",
    "\n",
    "- Improves search speed by reducing the computational complexity\n",
    "- Potentially reduces noise in the feature space\n",
    "- Helps mitigate the \"curse of dimensionality\" for high-dimensional data\n",
    "\n",
    "To use PCA, we set `use_pca=True` in the `load_reference` method and specify the number of components to keep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf412aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.load_reference(\n",
    "    path_to_sfd_folder='./sfddata-master',\n",
    "    use_pca=True,\n",
    "    num_pca_components=20,  # Keep 20 PCA components\n",
    ")\n",
    "\n",
    "neighbors_df = client.find_neighbors(\n",
    "    ztf_object_id='ZTF21abbzjeq',  # Using the test transient\n",
    "    n=5,\n",
    "    plot=True,\n",
    "    save_figures=True,\n",
    "    path_to_figure_directory='./figures'\n",
    ")\n",
    "print(\"\\nNearest neighbors using PCA:\")\n",
    "print(neighbors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0254e4d4",
   "metadata": {},
   "source": [
    "## 2. Creating and Using Theorized Lightcurves\n",
    "\n",
    "One powerful feature of reLAISS is the ability to use theorized (synthetic) lightcurves in the neighbor search. This allows you to:\n",
    "\n",
    "- Test theoretical models against observed data\n",
    "- Explore \"what-if\" scenarios by creating custom lightcurves\n",
    "- Find real transients that match your theoretical predictions\n",
    "\n",
    "When creating a theorized lightcurve, the DataFrame must have the following columns:\n",
    "- `ant_mjd`: Modified Julian Date (time)\n",
    "- `ant_mag`: Magnitude\n",
    "- `ant_magerr`: Magnitude error\n",
    "- `ant_passband`: Filter name ('g' for g-band, 'R' for r-band)\n",
    "- `ant_ra`: Right Ascension (optional)\n",
    "- `ant_dec`: Declination (optional)\n",
    "\n",
    "**Important:** When using a theorized lightcurve, you must also provide a `host_ztf_id` parameter to specify which host galaxy to use, since the theorized lightcurve doesn't have an associated host.\n",
    "\n",
    "Below, we create a simple Gaussian-shaped lightcurve and find its nearest neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34e906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a theorized lightcurve\n",
    "theorized_lc = create_theorized_lightcurve()\n",
    "\n",
    "# Find neighbors for the theorized lightcurve\n",
    "# Need to provide a host galaxy when using theorized lightcurve\n",
    "neighbors_df = client.find_neighbors(\n",
    "    theorized_lightcurve_df=theorized_lc,\n",
    "    host_ztf_id='ZTF21abbzjeq',  # Use this transient's host\n",
    "    n=5,\n",
    "    plot=True,\n",
    "    save_figures=True,\n",
    "    path_to_figure_directory='./figures'\n",
    ")\n",
    "print(\"\\nNearest neighbors for theorized lightcurve:\")\n",
    "print(neighbors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f079cad1",
   "metadata": {},
   "source": [
    "## 3. Swapping Host Galaxies\n",
    "\n",
    "reLAISS allows you to swap the host galaxy of a transient, which is useful for:\n",
    "\n",
    "- Exploring how host properties affect the similarity search results\n",
    "- Investigating the effects of different environments on transient characteristics\n",
    "- Testing hypotheses about host galaxy influences\n",
    "\n",
    "Here's how to swap in a different host galaxy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc52bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find neighbors with a swapped host galaxy\n",
    "neighbors_df = client.find_neighbors(\n",
    "    ztf_object_id='ZTF21abbzjeq',  # Source transient\n",
    "    host_ztf_id='ZTF21aakswqr',  # Host to swap in\n",
    "    n=5,\n",
    "    plot=True,\n",
    "    save_figures=True,\n",
    "    path_to_figure_directory='./figures'\n",
    ")\n",
    "print(\"\\nNearest neighbors with swapped host galaxy:\")\n",
    "print(neighbors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71893de",
   "metadata": {},
   "source": [
    "## 4. Setting Maximum Neighbor Distances\n",
    "\n",
    "Sometimes you're only interested in neighbors that are truly similar to your target. By setting a maximum distance threshold, you can:\n",
    "\n",
    "- Filter out neighbors that are too dissimilar\n",
    "- Focus only on highly confident matches\n",
    "- Avoid including poor matches just to reach a specific number of neighbors\n",
    "\n",
    "Note that you might get fewer neighbors than requested if the distance threshold is applied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3cde6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find neighbors with maximum distance constraint\n",
    "neighbors_df = client.find_neighbors(\n",
    "    ztf_object_id='ZTF21abbzjeq',\n",
    "    n=5,\n",
    "    max_neighbor_dist=0.5,  # Only return neighbors within this distance\n",
    "    plot=True,\n",
    "    save_figures=True,\n",
    "    path_to_figure_directory='./figures'\n",
    ")\n",
    "print(\"\\nNearest neighbors with maximum distance constraint:\")\n",
    "print(neighbors_df)\n",
    "print(f\"Number of neighbors found: {len(neighbors_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8462f6a5",
   "metadata": {},
   "source": [
    "## 5. Tweaking ANNOY Parameters\n",
    "\n",
    "ANNOY (Approximate Nearest Neighbors Oh Yeah) is the algorithm used for fast nearest neighbor search. You can tune its parameters to balance search accuracy and speed:\n",
    "\n",
    "- `search_k`: Controls the number of nodes to explore during search (higher = more accurate but slower)\n",
    "- `n_trees`: Controls the number of random projection trees built (set during client initialization)\n",
    "\n",
    "Here's how to adjust the search_k parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec26c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find neighbors with tweaked ANNOY parameters\n",
    "neighbors_df = client.find_neighbors(\n",
    "    ztf_object_id='ZTF21abbzjeq',\n",
    "    n=5,\n",
    "    search_k=2000,  # Increase search_k for more accurate results\n",
    "    plot=True,\n",
    "    save_figures=True,\n",
    "    path_to_figure_directory='./figures'\n",
    ")\n",
    "print(\"\\nNearest neighbors with tweaked ANNOY parameters:\")\n",
    "print(neighbors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dda240b",
   "metadata": {},
   "source": [
    "## 6. Making Corner Plots\n",
    "\n",
    "Corner plots are a powerful visualization tool that show the distribution of features for the input transient and its neighbors. They can help you:\n",
    "\n",
    "- Understand which features are driving the similarity matching\n",
    "- Identify potential correlations between different features\n",
    "- Visualize the feature space and where your transient sits within it\n",
    "\n",
    "To create corner plots, we need to first get the primer_dict containing information about the input transient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd30b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get neighbors from a new search\n",
    "neighbors_df = client.find_neighbors(\n",
    "    ztf_object_id='ZTF21abbzjeq',\n",
    "    n=5,\n",
    "    plot=True,\n",
    "    save_figures=True,\n",
    "    path_to_figure_directory='./figures'\n",
    ")\n",
    "\n",
    "# Get primer_dict separately\n",
    "from relaiss.search import primer\n",
    "primer_dict = primer(\n",
    "    lc_ztf_id='ZTF21abbzjeq',\n",
    "    theorized_lightcurve_df=None,\n",
    "    host_ztf_id=None,\n",
    "    dataset_bank_path=client.bank_csv,\n",
    "    path_to_timeseries_folder='./',\n",
    "    path_to_sfd_folder=client.path_to_sfd_folder,\n",
    "    lc_features=client.lc_features,\n",
    "    host_features=client.host_features,\n",
    "    num_sims=0,\n",
    "    save_timeseries=False,\n",
    "    preprocessed_df=client.get_preprocessed_dataframe()  # Use the preprocessed dataframe\n",
    ")\n",
    "\n",
    "# Create corner plots using the primer_dict\n",
    "from relaiss.plotting import corner_plot\n",
    "corner_plot(\n",
    "    neighbors_df=neighbors_df,\n",
    "    primer_dict=primer_dict,\n",
    "    path_to_dataset_bank=client.bank_csv,\n",
    "    path_to_figure_directory='./figures',\n",
    "    save_plots=True,\n",
    "    preprocessed_df=client.get_preprocessed_dataframe()  # Use the preprocessed dataframe\n",
    ")\n",
    "print(\"Corner plots saved to ./figures/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d723f47a",
   "metadata": {},
   "source": [
    "## 7. Advanced Anomaly Detection with Parameter Tuning\n",
    "\n",
    "The anomaly detection module in reLAISS uses an Isolation Forest algorithm that can be tuned for different scenarios. Key parameters include:\n",
    "\n",
    "- `n_estimators`: Number of base estimators (trees) in the ensemble\n",
    "- `contamination`: Expected proportion of outliers in the dataset\n",
    "- `max_samples`: Number of samples drawn to train each base estimator\n",
    "\n",
    "Let's explore how different parameters affect the model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from relaiss.anomaly import train_AD_model, anomaly_detection\n",
    "\n",
    "# Train models with different parameters to compare\n",
    "print(\"Training anomaly detection model with default parameters...\")\n",
    "default_model_path = train_AD_model(\n",
    "    lc_features=client.lc_features,\n",
    "    host_features=client.host_features,\n",
    "    path_to_dataset_bank=client.bank_csv,\n",
    "    path_to_sfd_folder='./sfddata-master',\n",
    "    path_to_models_directory=\"./models\",\n",
    "    n_estimators=100,\n",
    "    contamination=0.02,\n",
    "    max_samples=256,\n",
    "    force_retrain=True,\n",
    "    preprocessed_df=client.get_preprocessed_dataframe()  # Use the preprocessed dataframe\n",
    ")\n",
    "\n",
    "print(\"Training anomaly detection model with more trees...\")\n",
    "model_more_trees_path = train_AD_model(\n",
    "    lc_features=client.lc_features,\n",
    "    host_features=client.host_features,\n",
    "    path_to_dataset_bank=client.bank_csv,\n",
    "    path_to_sfd_folder='./sfddata-master',\n",
    "    path_to_models_directory=\"./models\",\n",
    "    n_estimators=200,  # More trees\n",
    "    contamination=0.02,\n",
    "    max_samples=256,\n",
    "    force_retrain=True,\n",
    "    preprocessed_df=client.get_preprocessed_dataframe()  # Use the preprocessed dataframe\n",
    ")\n",
    "\n",
    "print(\"Training anomaly detection model with higher contamination...\")\n",
    "model_higher_contam_path = train_AD_model(\n",
    "    lc_features=client.lc_features,\n",
    "    host_features=client.host_features,\n",
    "    path_to_dataset_bank=client.bank_csv,\n",
    "    path_to_sfd_folder='./sfddata-master',\n",
    "    path_to_models_directory=\"./models\",\n",
    "    n_estimators=100,\n",
    "    contamination=0.05,  # Higher contamination\n",
    "    max_samples=256,\n",
    "    force_retrain=True,\n",
    "    preprocessed_df=client.get_preprocessed_dataframe()  # Use the preprocessed dataframe\n",
    ")\n",
    "\n",
    "# Run anomaly detection with default model\n",
    "print(\"\\nRunning anomaly detection with default model...\")\n",
    "anomaly_detection(\n",
    "    transient_ztf_id=\"ZTF21abbzjeq\",\n",
    "    lc_features=client.lc_features,\n",
    "    host_features=client.host_features,\n",
    "    path_to_timeseries_folder=\"./timeseries\",\n",
    "    path_to_sfd_folder='./sfddata-master',\n",
    "    path_to_dataset_bank=client.bank_csv,\n",
    "    path_to_models_directory=\"./models\",\n",
    "    path_to_figure_directory=\"./figures/AD_default\",\n",
    "    save_figures=True,\n",
    "    n_estimators=100,\n",
    "    contamination=0.02,\n",
    "    max_samples=256,\n",
    "    force_retrain=False,\n",
    "    preprocessed_df=client.get_preprocessed_dataframe()  # Use the preprocessed dataframe\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ce97f2",
   "metadata": {},
   "source": [
    "## 8. Anomaly Detection with Host Swapping\n",
    "\n",
    "Just as with neighbor searches, you can swap host galaxies for anomaly detection. This helps you understand how host properties contribute to a transient's anomaly score.\n",
    "\n",
    "This feature is particularly useful for:\n",
    "- Testing if the anomalous nature of a transient is due to its host galaxy\n",
    "- Exploring the \"what if\" scenario of a transient occurring in a different environment\n",
    "- Separating intrinsic transient anomalies from host-related factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b1ee2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the default model but swap in a different host galaxy\n",
    "anomaly_detection(\n",
    "    transient_ztf_id=\"ZTF21abbzjeq\",\n",
    "    lc_features=client.lc_features,\n",
    "    host_features=client.host_features,\n",
    "    path_to_timeseries_folder=\"./timeseries\",\n",
    "    path_to_sfd_folder='./sfddata-master',\n",
    "    path_to_dataset_bank=client.bank_csv,\n",
    "    host_ztf_id_to_swap_in=\"ZTF20aacbyec\",  # Swap in a different host\n",
    "    path_to_models_directory=\"./models\",\n",
    "    path_to_figure_directory=\"./figures/AD_host_swap\",\n",
    "    save_figures=True,\n",
    "    n_estimators=100,\n",
    "    contamination=0.02,\n",
    "    max_samples=256,\n",
    "    force_retrain=False,\n",
    "    preprocessed_df=client.get_preprocessed_dataframe()  # Use the preprocessed dataframe\n",
    ")\n",
    "\n",
    "print(\"Anomaly detection figures saved to ./figures/AD_default/ and ./figures/AD_host_swap/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81b896e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "By combining these features, you can create highly customized searches tailored to your specific research questions.\n",
    "\n",
    "For information on how to build your own dataset bank for reLAISS, see the `build_databank.ipynb` notebook."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
